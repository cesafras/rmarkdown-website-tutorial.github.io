---
title: "A Literary Social Network"
output: html_document
---
***
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)
library(stringr)
library(ggplot2)
library(rJava)
library(NLP)
library(openNLP)
library(dplyr)
library(igraph)
library(networkD3)
library(knitr)
library(data.table)
library(egg)
library(gridExtra)
library(ggpubr)
library(highcharter)
library(plotly)
library(htmlwidgets)
library(tweetrmd)
library(webshot2)
library(emo)
```

```{r palettes, echo=FALSE}
# Color palettes: for this analysis we use Darjeeling1
wes_palettes <- list(
  BottleRocket1 = c("#A42820", "#5F5647", "#9B110E", "#3F5151", "#4E2A1E", "#550307", "#0C1707"),
  BottleRocket2 = c("#FAD510", "#CB2314", "#273046", "#354823", "#1E1E1E"),
  Rushmore1 = c("#E1BD6D", "#EABE94", "#0B775E", "#35274A" ,"#F2300F"),
  Rushmore = c("#E1BD6D", "#EABE94", "#0B775E", "#35274A" ,"#F2300F"),
  Royal1 = c("#899DA4", "#C93312", "#FAEFD1", "#DC863B"),
  Royal2 = c("#9A8822", "#F5CDB4", "#F8AFA8", "#FDDDA0", "#74A089"),
  Zissou1 = c("#3B9AB2", "#78B7C5", "#EBCC2A", "#E1AF00", "#F21A00"),
  Darjeeling1 = c("#FF0000", "#00A08A", "#F2AD00", "#F98400", "#5BBCD6"),
  Darjeeling2 = c("#ECCBAE", "#046C9A", "#D69C4E", "#ABDDDE", "#000000"),
  Chevalier1 = c("#446455", "#FDD262", "#D3DDDC", "#C7B19C"),
  FantasticFox1 = c("#DD8D29", "#E2D200", "#46ACC8", "#E58601", "#B40F20"),
  Moonrise1 = c("#F3DF6C", "#CEAB07", "#D5D5D3", "#24281A"),
  Moonrise2 = c("#798E87", "#C27D38", "#CCC591", "#29211F"),
  Moonrise3 = c("#85D4E3", "#F4B5BD", "#9C964A", "#CDC08C", "#FAD77B"),
  Cavalcanti1 = c("#D8B70A", "#02401B", "#A2A475", "#81A88D", "#972D15"),
  GrandBudapest1 = c("#F1BB7B", "#FD6467", "#5B1A18", "#D67236"),
  GrandBudapest2 = c("#E6A0C4", "#C6CDF7", "#D8A499", "#7294D4"),
  IsleofDogs1 = c("#9986A5", "#79402E", "#CCBA72", "#0F0D0E", "#D9D0D3", "#8D8680"),
  IsleofDogs2 = c("#EAD3BF", "#AA9486", "#B6854D", "#39312F", "#1C1718")
)

# If you need more colours than normally found in a palette, you
# can use a continuous palette to interpolate between existing
# colours:
# pal <- wes_palette(21, name = "Zissou1", type = "continuous")
wes_palette <- function(name, n, type = c("discrete", "continuous")) {
  type <- match.arg(type)
  
  pal <- wes_palettes[[name]]
  if (is.null(pal))
    stop("Palette not found.")
  
  if (missing(n)) {
    n <- length(pal)
  }
  
  if (type == "discrete" && n > length(pal)) {
    stop("Number of requested colors greater than what palette can offer")
  }
  
  out <- switch(type,
                continuous = grDevices::colorRampPalette(pal)(n),
                discrete = pal[1:n]
  )
  structure(out, class = "palette", name = name)
}
```

```{r data, echo=FALSE}
# Read in the data frame.
# https://docs.google.com/spreadsheets/d/1ZMf-UDG7AIarLH393TH7oKRzF-XkMN_qt5pVFz-8Hv4/edit?resourcekey=0-3Z9_rgI4qtmTyJMLZLcCDQ#gid=745766201
dedup <- read.csv("~/Downloads/Personal Project Acknowledgements - center for fiction.csv", na.strings = " ")

# Filter for just 2020
#dedup <- dedup[dedup$Year == 2020,]

# Format all of the strings in the acknowledgments field to exclude single quotes.
# We exclude these because if we leave them in it escapes the string and throws
# an error.
dedup$Text <- gsub("'", '', dedup$Text)

# Remove all the authors for whom we don't have any acknowledgment info (yet.)
dedup <- dedup %>% filter(Text != "")
```

```{r nlp, echo=FALSE}
# use NLPs NER annotator to identify person & location entities
sent_annot = Maxent_Sent_Token_Annotator()
word_annot = Maxent_Word_Token_Annotator()
org_annot <- Maxent_Entity_Annotator(kind = "organization") #annotate location
loc_annot = Maxent_Entity_Annotator(kind = "location") #annotate location
people_annot = Maxent_Entity_Annotator(kind = "person") #annotate person
```

```{r process, echo=FALSE}
# We want to create a data frame that stores both the thanker and the thankee
# for each set of acknowledgments. This requires us to loop through the original
# data frame extracting all of the names and appending the thankees with the name
# of the thanker.

# This will be a loop
# Make a list of the thankees for a single author
# The "text" variable is the Text field from each row of data
# This becomes the list of text_people which becomes the field called "thankee"
# The name of the author from the corresponding row is appended to each of the
# "thankees" in a column called "thanker"
# Repeat this operation for every row in the data frame

df_people <- data.frame()
df_orgs <- data.frame()

for (i in 1:nrow(dedup))
{
  text <- dedup[i,]$Text
  text = as.String(text)
  annot.l1 = NLP::annotate(text, list(sent_annot,word_annot,people_annot,org_annot))
  k <- sapply(annot.l1$features, `[[`, "kind")
  text_people = text[annot.l1[k == "person"]]
  text_orgs = text[annot.l1[k == "organization"]]
  
  if (length(text_people)>0) {
    df_1 <- as.data.frame(
      cbind(entity_1 = as.character(rep(dedup[i,]$Author,length(text_people))),
            entity_2 = text_people))
  } else {
    df_1 <- data.frame()
  }
  
  if (length(text_orgs)>0) {
    df_2 <- as.data.frame(
      cbind(entity_1 = as.character(rep(dedup[i,]$Author,length(text_orgs))),
            entity_2 = text_orgs))
  } else {
    df_2 <- data.frame()
  }
  
  df_people <- rbind(df_people, df_1)
  df_orgs <- rbind(df_orgs, df_2)
}

####
# Rename some entities that I know are wrong (manual operation)
####

# Format as character for string functions.
df_people$entity_2 <- as.character(df_people$entity_2)
df_orgs$entity_2 <- as.character(df_orgs$entity_2)

# Rename the entities that are labeled incorrectly
df_people[df_people$entity_2 == "Pam Zhang","entity_2"] <- "C Pam Zhang"
df_people[df_people$entity_2 %in% c("Lan Samantha Chang","Sam Chang", "Samantha Chang"),"entity_2"] <- "Lan Samantha Chang"
df_people[df_people$entity_2 == "Ira Silverberg-you","entity_2"] <- "Ira Silverberg"
df_orgs[df_orgs$entity_2 == "ICM Partners","entity_2"] <- "ICM"
df_orgs[df_orgs$entity_2 %in% c("Hunter","Colleges MFA"),"entity_2"] <- "Hunter College"

# Remove some entities
# Remove: School, University, Bath, MFA
remove_entities_orgs <- c("School", "University", "Bath", "MFA", "The","Dana")
df_orgs <- df_orgs[-which(df_orgs$entity_2 %in% remove_entities_orgs),]
remove_entities_people <- c("Hunter Colleges MFA")
df_people <- df_people[-which(df_people$entity_2 %in% remove_entities_people),]

#####
# Remove single names from people df (except for the most popular first name)
#####

# Determine the most thanked first name. Remove all other first name onlies.
calculate_mode <- function(x) {
  uniqx <- unique(na.omit(x))
  uniqx[which.max(tabulate(match(x, uniqx)))]
}

modal_name <- calculate_mode(df_people$entity_2)

df_people <- df_people[which(sapply(strsplit(df_people$entity_2, " "), length)>1 | 
                               df_people$entity_2 == modal_name),]

# Remove from the master list any person entity that is also the writer
# (entity_1)'s agent. (This is so that we only have writers connecting to
# agencies in the diagram and not writer > agent > agency which would be more
# cluttered.)

dedup <- dedup %>%
  mutate(author_agent_concat = paste(Author,Agent))

df_people <- df_people %>%
  mutate(author_agent_concat = paste(entity_1,entity_2))

df_people <- anti_join(df_people, dedup)

####
# Add some organizations that I know are missing (manual operation)
####

# Make a data frame with all of the authors + manual organizations
# Organization names (manual list because the model doesn't get literary orgs)
org_list <- c("Aspen Words", "Bread Loaf", "MacDowell", "Sewanee", "Tin House",
              "VONA", "Yaddo", "Whiting Foundation", "Civitella Ranieri",
              "PEN America", "Hedgebrook", "Millay", "Vermont Studio Center")

df_orgs_manual <- data.frame()

for (i in 1:length(org_list))
{
  df_3 <- dedup %>% filter(grepl(org_list[i], Text)) %>% select(Author)
  
  if (nrow(df_3)>0) {
    df_3 <- as.data.frame(
      cbind(entity_1 = as.character(df_3$Author),
            entity_2 = as.character(rep(org_list[i],length(df_3$Author)))))
  } else {
    df_3 <- data.frame()
  }
  
  df_orgs_manual <- rbind(df_orgs_manual, df_3)
}

df_orgs <- rbind(df_orgs, df_orgs_manual)

# Remove agencies from orgs df. Remove from the list any org entity that is also
# the writer's agency. (We will add agencies back later.)
dedup <- dedup %>%
  mutate(author_agency_concat = paste(Author,Agency))

df_orgs <- df_orgs %>%
  mutate(author_agency_concat = paste(entity_1,entity_2))

df_orgs <- anti_join(df_orgs, dedup)

# Join all three tables to make one master table:
# This includes the people table (with agents excluded) and
# the orgs table (with manual orgs added and agencies stripped out)
df_total <- rbind(df_people[c("entity_1","entity_2")], 
                  df_orgs[c("entity_1","entity_2")])

# Remove all duplicate rows (we just want one match per entity pair.)
df_total <- unique(df_total)

####
# Make a list of all the entities to include in the network.
# Remove all rows in which entity_2 is not duplicated (i.e. an entity who was
# acknowledged by only one writer, in which case we don't consider them a
# member of the network)
####

# Make the list: every single entity that appears as a thanker or a thankee
df_total_e1 <- data.frame(entity = df_total[,"entity_1"])
df_total_e2 <- data.frame(entity = df_total[,"entity_2"])
df_total_include <- rbind(df_total_e1, df_total_e2)

df_total_include <- as.vector(
  df_total_include[df_total_include$entity %in% 
                     names(which(table(df_total_include$entity) > 1)), ])

# Select only the entity_2s from df_total that are also in the list of 
# df_total_includes
df_total <- df_total %>% filter(entity_2 %in% df_total_include)

# Make a data frame with all of the authors + agencies: i.e. add back the
# agencies to the completed dataset (we treat these differently than other
# entities, because if a writer is the only entity_1 associated with an agency
# we still want to include it, i.e. it doesn't need to satisfy the > 1 filter.
df_agency <- data.frame(entity_1 = dedup[,"Author"],
                        entity_2 = dedup[,"Agency"])

# Make a data frame with all of the authors + MFA programs: same logic as above
# TODO(remove the org entities from entity_2 that match the MFA in the remove
# agencies step)
df_mfa <- data.frame(entity_1 = dedup[,"Author"],
                     entity_2 = dedup[,"MFA"])

# Add the agency and MFA data frames to the person / org data frame. (Remember
# that we are doing this at the end to ensure that when a writer is the only
# person represented by their agency, the agency still appears in the network.)
df_total <- rbind(df_total[c("entity_1","entity_2")], 
                  df_agency[c("entity_1","entity_2")],
                  df_mfa[c("entity_1","entity_2")]
                  )

# Manually inspect the data frame in google sheets.
# write.csv(df_total,"~/Downloads/publishing_data_export.csv")
# df_total <- read.csv("~/Downloads/publishing data manual cleanup - publishing_data_export.csv")

# Remove rows with empty connections
df_total <- df_total[df_total$entity_2 != "",]
```

```{r graph_analysis, echo = FALSE}
####
# Generate a directed igraph object in order to calculate the degree for each
# entity being thanked.
####
# Turn data frame into a directed igraph object.
g_for_deg <- graph_from_data_frame(d=df_total[c("entity_1","entity_2")], directed=T)

# Calculate the degree for each node where the entity is the one being thanked:
deg <- degree(g_for_deg, mode="in")

####
# Generate an undirected igraph object to build the network.
####
# Turn data frame into an undirected igraph object.
g <- graph_from_data_frame(d=df_total[c("entity_1","entity_2")], directed=F)

# Assign each entity to a community
clp <- cluster_label_prop(g)
#https://igraph.org/r/doc/cluster_edge_betweenness.html
ceg <- cluster_edge_betweenness(g)
```

``` {r forcenetwork, out.width="100%", out.height="800px", echo = FALSE}
#Convert igraph object to networkD3 object
g_d3 <- igraph_to_networkD3(g)
df_nodes <- g_d3$nodes
df_links <- g_d3$links

# Add grouping variable to the nodes list
df_nodes <- df_nodes %>%
  mutate(group =
           ifelse(name %in% dedup$Author, "Debut Author",
                  ifelse(name %in% df_agency$entity_2, "Agency",
                         ifelse(name %in% df_orgs$entity_2, "Organization",
                                "Individual"))))
# Fix the fact that a number of universities are in the df_people df
df_nodes[df_nodes$name %like% c("University"),"group"] <- "Organization"
df_nodes[df_nodes$name == "Morgan Entrekin","group"] <- "Individual"
df_nodes[df_nodes$name == "Syracuse","group"] <- "Organization"

# Make a JS readable color scale to distinguish among the different groups 
# (based on our Darjeeling1 Wes Anderson palette)
ColourScale <- 'd3.scaleOrdinal()
            .domain(["Debut Author", "Agency", "Organization", "Individual"])
           .range(["#FF0000", "#F2AD00", "#00A08A", "#5BBCD6"]);'

# Add in the degreeness for each entity to determine the bubble size
df_deg <- tibble::rownames_to_column(data.frame(deg), "name")
df_nodes <- left_join(df_nodes, df_deg)

# Scale up the degreeness factor so that the circles are bigger and easier to
# views.
df_nodes <- df_nodes %>% mutate(deg = deg^3)

# Final force network
forceNetwork(Links = df_links, Nodes = df_nodes,
             Source = 'source', 
             Target = 'target', 
             NodeID = 'name',
             Group = 'group',
             linkColour = "FFFFFF",
             Nodesize = 3,
             fontSize=14,
             legend=T,
             opacity = .8,
             bounded = F,
             opacityNoHover = .4,
             #charge = -10,
             colourScale = JS(ColourScale))
```

<span style='color: red; font-weight: bold'>The graphic above is a social network constructed of the  people (and organizations) mentioned in the acknowledgements sections of 80 novels longlisted for the [Center for Fiction First Novel Prize](https://centerforfiction.org/grants-awards/the-first-novel-prize/).</span>

> TL;DR

Each node (bubble) in the graph is color coded based on whether the entity is a:

* debut author
* agency
* other organization (e.g. workshop, residency, MFA program)
* an individual / friend

The bigger the node and the closer the node to the center of the graph the more
influential that bubble is within social network. "Influential" here just means
that more novelists have mentioned that particular entity in their
acknowledgements. So the biggest bubble ([Bread Loaf](https://www.middlebury.edu/writers-conferences/)) represents the node in the
network that is most influential (i.e. was mentioned by the most novelists.)

You can hover or click on the nodes / bubbles to see what other entities they are
connected to. You can also drag the nodes around to see what amount of force
they exert on the network. (The more the network moves with the node, the
bigger its influence.)

> Background

One of the most oft repeated pieces of advice for aspiring writers looking for
literary agents is to look at the acknowledgements section of novels to see
which literary agents represent the writers they admire. From there, the advice
goes, just query those agents and, with a bit of work and kismit, one day 
*you'll* be the published author whose acknowledgements people are trawling.

Okay, then!

The rest of this analysis is me taking that advice... too far? Sure I could have
read the acknowledgements, made my list of literary agents and gone about my
business, but... why not make it a thing?

So. I created a dataset consisting of all of the debut authors that had been
nominated for the Center for Fiction First Novel Prize in the past three years
(2020, 2019, 2018) and did some analysis, based on... you guessed it, the
contents of their acknowledgements. In a perfect world, I could do this for
every single debut author, ever, but in practice I needed to limit the size of
the dataset and chose this particular group of ~80 writers because it seemed
like a somewhat representative cohort of fiction that I enjoy and that have also
enjoyed some level of acclaim (owing to the prize nomination and all.) Why debut
novelists you ask? Well, one, because I am marching toward my own debut. But two,
technically speaking, it meant that writers would not be duplicated in the
dataset year over year, because you're only a debut novelist once. (Anything
that makes my life easier!)

From there I really only had a couple of questions:

* Is every writer friends with every other writer, or is that a myth perpetuated
by literary Twitter?
* And speaking of literary Twitter, is [Alexander Chee](https://twitter.com/alexanderchee) the most beloved individual
in the writing community?

To put my intuition to the test I constructed the social graph you see before
you, which is comprised of every person, place, or thing mentioned each novel's acknowledgements. (If the person, place or thing was only mentioned by one
writer, though, I didn't include it.) To build the dataset I used a natural
language processing model to extract all of the named entities (i.e. the people,
places, and things) from the text of each author's acknowledgements. (The
text content of each acknowledgement was scraped from a combination of Google
Books, Amazon, and [Axis360](https://sfpl.axis360.baker-taylor.com/), the digital library.)

Note that there are two major limitations with my approach which I will call
out now:

* Just because someone isn't acknowledged by a writer doesn't mean that person
isn't in that writer's social network.
* Our natural language processing model isn't perfect so sometimes it
  + Miscategorizes entities (e.g. assumes Sewanee is a place not an organization)
  + Doesn't properly recognize entities (e.g. Iowa is distinct from University of
  Iowa)
  
The second problem is easier to address than the first, so I did try to clean 
the data manually a bit, but it probably still isn't perfect. (e.g. Curtis Brown
is actually an organization but may be labeled as an individual.) But I think
it's good enough for government work. The first problem is kind of a
philosophical one and I'm just going to assert here that if a writer didn't
acknowledge an entity in the approximately 2,500 words the average author 
allocated to their acknowledgements, that that entity is not in that writer's inner
circle.

I hope that makes sense! (It's actually slightly more messy / complicated than
I'm making it out to be. If you're interested in the source code, [here](https://github.com/cesafras/vigilant-adventure/blob/gh-pages/first_observations.Rmd) it is.)

*Note also: I did not really check my work, however I did watch a conversation
between [Lucy Tan](https://lucyrtan.com/) and [Susie Yang](https://www.susiebooks.com/) hosted by everyone's favorite Brooklyn bookstore
[Books Are Magic](https://www.booksaremagic.net/) in which they revealed a long-standing friendship, so the fact
that they show up so close together in the graph is... super vindicating.*

> Learnings

Basically, yes, Alexander Chee is the most popular person in the literary community.

Also, apply to Bread Loaf?